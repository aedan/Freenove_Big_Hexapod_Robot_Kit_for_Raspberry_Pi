# Autonomous Hexapod Robot System

## Overview

Your hexapod robot now has autonomous capabilities! It can:
- **Explore** like a curious kid - wander around, avoid obstacles, learn about its environment
- **Recognize faces** - remember people and greet known faces
- **Patrol** - follow a route and alert when unknown people are detected
- **Learn** - build a memory of faces and spatial awareness

Think of it as a robotic "guard dog" that learns and adapts!

## Features

### 1. Exploration Mode üîç
The robot wanders around randomly, avoiding obstacles:
- Random forward movement and turning
- Ultrasonic obstacle detection and avoidance
- Pauses to scan environment with camera
- Builds spatial memory of visited areas

**Best for**: Learning about a new environment, general autonomous operation

### 2. Patrol Mode üö®
The robot follows predefined waypoints and watches for intruders:
- Follows patrol route waypoints
- Scans for faces at each position
- Alerts with buzzer when unknown person detected
- Greets known faces with friendly chirp

**Best for**: Home security, monitoring areas

### 3. Face Recognition üë§
The robot remembers people:
- Detects faces using camera
- Recognizes known people (trained faces)
- Alerts on unknown faces
- Stores face database persistently

### 4. Obstacle Avoidance üõ°Ô∏è
Reactive navigation using ultrasonic sensor:
- Detects obstacles < 30cm away
- Backs up and turns to avoid
- Returns to previous behavior after clearing

## Setup Requirements

### Hardware
- ‚úÖ Camera (already configured)
- ‚úÖ Ultrasonic sensor (already installed)
- ‚úÖ IMU (for orientation)
- ‚úÖ Buzzer (for alerts)
- ‚úÖ LEDs (for status indication)

### Software Dependencies
Install OpenCV with face recognition support:

```bash
# Install opencv-contrib-python for face recognition
sudo pip3 install opencv-contrib-python

# Or if already installed:
sudo pip3 install --upgrade opencv-contrib-python
```

### Directory Structure
The system automatically creates:
```
Code/Server/
‚îú‚îÄ‚îÄ face_data/              # Face recognition data
‚îÇ   ‚îú‚îÄ‚îÄ face_model.yml     # Trained model
‚îÇ   ‚îú‚îÄ‚îÄ face_database.json # Face metadata
‚îÇ   ‚îî‚îÄ‚îÄ images/            # Training images
‚îÇ       ‚îú‚îÄ‚îÄ 1.0.jpg        # Face ID 1, sample 0
‚îÇ       ‚îú‚îÄ‚îÄ 1.1.jpg        # Face ID 1, sample 1
‚îÇ       ‚îî‚îÄ‚îÄ ...
```

## Usage Guide

### Quick Start

#### 1. Train Faces (First Time Setup)

Capture face samples for people you want the robot to recognize:

```python
# From client, send commands:
CMD_CAPTURE_FACE_SAMPLE#Alice
CMD_CAPTURE_FACE_SAMPLE#Bob
# ... repeat 5-10 times per person from different angles

# Train the recognizer:
CMD_TRAIN_FACES
```

**Tip**: Capture multiple samples (5-10) per person from different:
- Angles (left, right, straight)
- Distances (close, far)
- Lighting conditions

#### 2. Start Exploration Mode

```python
CMD_START_EXPLORING
```

The robot will:
- Wander around randomly
- Avoid obstacles automatically
- Scan for faces periodically
- Chirp when it sees known faces
- Alert (buzzer) when it sees unknown faces

#### 3. Set Up Patrol Mode

First, define patrol waypoints (movement commands):

```python
# Add waypoints (movement commands)
CMD_ADD_PATROL_WAYPOINT#CMD_MOVE#40#0#0#0#tripod   # Forward
CMD_ADD_PATROL_WAYPOINT#CMD_MOVE#0#40#0#0#tripod   # Turn right
CMD_ADD_PATROL_WAYPOINT#CMD_MOVE#40#0#0#0#tripod   # Forward
CMD_ADD_PATROL_WAYPOINT#CMD_MOVE#0#-40#0#0#tripod  # Turn left

# Start patrol:
CMD_START_PATROL
```

The robot will:
- Follow waypoints in sequence
- Loop back to start after last waypoint
- Pause and scan for faces at each waypoint
- Alert on unknown faces (buzzer + red LEDs)
- Greet known faces (chirp + green LEDs)

#### 4. Stop Autonomous Mode

```python
CMD_STOP_AUTONOMOUS
```

### Command Reference

#### Autonomous Control
| Command | Format | Description |
|---------|--------|-------------|
| `CMD_START_EXPLORING` | `CMD_START_EXPLORING` | Start exploration mode |
| `CMD_START_PATROL` | `CMD_START_PATROL` | Start patrol mode |
| `CMD_STOP_AUTONOMOUS` | `CMD_STOP_AUTONOMOUS` | Stop autonomous operation |
| `CMD_ADD_PATROL_WAYPOINT` | `CMD_ADD_PATROL_WAYPOINT#<movement_cmd>` | Add waypoint to patrol route |

#### Face Recognition
| Command | Format | Description |
|---------|--------|-------------|
| `CMD_CAPTURE_FACE_SAMPLE` | `CMD_CAPTURE_FACE_SAMPLE#<name>` | Capture face sample for person |
| `CMD_TRAIN_FACES` | `CMD_TRAIN_FACES` | Train face recognizer with all samples |
| `CMD_LIST_KNOWN_FACES` | `CMD_LIST_KNOWN_FACES` | List all known faces in database |
| `CMD_DELETE_FACE` | `CMD_DELETE_FACE#<face_id>` | Delete a face from database |

### Behavior Parameters

You can adjust these in `autonomous.py`:

```python
# Obstacle detection
obstacle_distance_threshold = 30.0  # cm - trigger avoidance
safe_distance = 50.0               # cm - consider clear

# Exploration
exploration_move_duration = 2.0     # seconds per move
exploration_turn_probability = 0.3  # 30% chance to turn
exploration_pause_duration = 1.0    # seconds to pause and scan

# Patrol
patrol_pause_duration = 2.0         # seconds at each waypoint

# Face detection
face_check_interval = 1.0           # seconds between checks
unknown_face_alert_duration = 5.0   # seconds to alert
```

## How It Works

### State Machine

```
IDLE
  ‚Üì
EXPLORING ‚Üê‚Üí OBSTACLE_AVOIDANCE
  ‚Üì
INVESTIGATING (face detected)
  ‚Üì
ALERT (unknown face) or return to EXPLORING
```

Patrol mode uses similar states but follows waypoints instead of random movement.

### Face Recognition Pipeline

1. **Camera captures frame** (640x480 BGR)
2. **Haar Cascade detects faces** (bounding boxes)
3. **LBPH recognizer identifies face**
   - Confidence < 100: Known person
   - Confidence > 100: Unknown person
4. **Trigger action**:
   - Known: Friendly chirp, green LED
   - Unknown: Buzzer alarm, red LED

### Obstacle Avoidance Algorithm

```
1. Check distance continuously
2. If distance < 30cm:
   a. Stop movement
   b. Back up 1 second
   c. Turn randomly (left or right)
   d. Resume previous behavior
```

## Advanced Features

### Custom Event Callbacks

You can add custom behavior when faces are detected:

```python
# In control.py _ensure_autonomous_initialized():

def on_unknown_face(face):
    # Custom action for unknown faces
    logger.warning(f"Intruder detected!")
    # Send notification, take photo, etc.

def on_known_face(face):
    # Custom action for known faces
    logger.info(f"Welcome back, {face['name']}!")
    # Play sound, move toward person, etc.

autonomous_controller.on_unknown_face_callback = on_unknown_face
autonomous_controller.on_known_face_callback = on_known_face
```

### Spatial Memory

The robot builds a simple occupancy grid:
- 20x20 grid, 50cm cells
- Tracks visited locations
- Marks obstacles
- Can be used for path planning (future enhancement)

Access via:
```python
exploration_score = autonomous_controller.spatial_memory.get_exploration_score()
# Returns percentage of area explored
```

### Buzzer Alert Patterns

**Unknown Person Alert**:
```
BEEP (0.2s) - pause (0.2s) - BEEP (0.2s) - pause (0.2s) - repeat
```

**Known Person Chirp**:
```
BEEP (0.1s) - done
```

## Troubleshooting

### "No module named 'cv2.face'"

Install opencv-contrib-python:
```bash
sudo pip3 install opencv-contrib-python
```

### "Camera initialization failed"

Check camera is enabled and working:
```bash
# Test camera
libcamera-still -o test.jpg

# Check camera in config
grep "camera_auto_detect" /boot/firmware/config.txt  # Should be "0"
grep "dtoverlay" /boot/firmware/config.txt            # Should have camera overlay
```

### "Ultrasonic sensor not responding"

Check GPIO connections:
- Trigger pin: GPIO 27
- Echo pin: GPIO 22

Test sensor:
```bash
cd Code/Server
python3 ultrasonic.py
```

### Face recognition not accurate

- **Capture more samples**: 10-15 per person recommended
- **Vary angles and lighting**: Capture in different conditions
- **Retrain after adding samples**: `CMD_TRAIN_FACES`
- **Adjust confidence threshold**: In `face_recognition.py`, change `confidence_threshold`

### Robot keeps getting stuck

- **Increase safe distance**: Edit `safe_distance` in `autonomous.py`
- **Improve obstacle detection**: Check ultrasonic sensor positioning
- **Add more patrol waypoints**: Smoother patrol route

## Example Scenarios

### Home Security Patrol

```python
# 1. Train family members
for person in ["Alice", "Bob", "Charlie"]:
    # Position person in front of camera
    for i in range(10):
        CMD_CAPTURE_FACE_SAMPLE#{person}
        time.sleep(1)

CMD_TRAIN_FACES

# 2. Set up patrol route (rectangle)
CMD_ADD_PATROL_WAYPOINT#CMD_MOVE#50#0#0#0#tripod   # Forward
CMD_ADD_PATROL_WAYPOINT#CMD_MOVE#0#40#0#0#tripod   # Turn right
CMD_ADD_PATROL_WAYPOINT#CMD_MOVE#50#0#0#0#tripod   # Forward
CMD_ADD_PATROL_WAYPOINT#CMD_MOVE#0#40#0#0#tripod   # Turn right
CMD_ADD_PATROL_WAYPOINT#CMD_MOVE#50#0#0#0#tripod   # Forward
CMD_ADD_PATROL_WAYPOINT#CMD_MOVE#0#40#0#0#tripod   # Turn right
CMD_ADD_PATROL_WAYPOINT#CMD_MOVE#50#0#0#0#tripod   # Forward
CMD_ADD_PATROL_WAYPOINT#CMD_MOVE#0#40#0#0#tripod   # Turn right (back to start)

# 3. Start patrol
CMD_START_PATROL

# Robot now patrols and alerts on unknown faces!
```

### Exploration and Learning

```python
# Just let it explore and learn
CMD_START_EXPLORING

# When it sees an unknown face, label them:
CMD_STOP_AUTONOMOUS
CMD_CAPTURE_FACE_SAMPLE#NewPerson
# Capture multiple times from different angles
CMD_CAPTURE_FACE_SAMPLE#NewPerson
CMD_CAPTURE_FACE_SAMPLE#NewPerson
# ... repeat 5-10 times

CMD_TRAIN_FACES
CMD_START_EXPLORING  # Resume exploration

# Now the robot knows this person!
```

## Performance Tips

1. **Camera frame rate**: Autonomous mode captures frames on-demand (not streaming), so no performance impact
2. **Face detection interval**: Checks every 1 second (adjustable)
3. **CPU usage**:
   - Idle: ~5%
   - Exploring: ~15-20%
   - Face detection: +10-15% during check
4. **Battery life**: Autonomous mode uses same power as manual control

## Future Enhancements

Potential additions you could implement:

- **Voice recognition**: Respond to spoken commands
- **Object detection**: Recognize toys, obstacles, specific objects
- **Path planning**: A* pathfinding with spatial memory
- **Remote notifications**: Send alerts via network when unknown faces detected
- **Follow mode**: Track and follow a specific person
- **Return home**: Navigate back to starting position
- **Learning routines**: Adapt patrol route based on activity patterns

## Files Overview

| File | Purpose |
|------|---------|
| `face_recognition.py` | Face detection and recognition using OpenCV LBPH |
| `autonomous.py` | Autonomous behavior state machine and control |
| `control.py` | Main control system with autonomous integration |
| `command.py` | Command definitions including autonomous commands |
| `camera.py` | Camera interface with frame capture |
| `ultrasonic.py` | Ultrasonic sensor for obstacle detection |

## Support

If you encounter issues or have questions:

1. Check the logs: `Code/Server/logs/` (if file logging enabled)
2. Test components individually (camera, ultrasonic, face recognition)
3. Verify all dependencies installed
4. Review command formats in this guide

## Credits

Built on top of the Freenove Hexapod Robot Kit with:
- OpenCV for computer vision
- LBPH face recognizer
- State machine architecture
- Event-driven design

---

**Have fun with your autonomous robot! ü§ñ**
